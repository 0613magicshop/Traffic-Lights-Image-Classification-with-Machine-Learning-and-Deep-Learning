{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GqLr7vU9t9rz"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, AveragePooling2D, Dense, Flatten, Dropout, Rescaling, RandomTranslation, RandomRotation, RandomZoom, RandomContrast, LeakyReLU, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam, Adadelta\n","from tensorflow.keras.applications import ResNet50V2, Xception, EfficientNetB0, DenseNet121\n","import pathlib\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import cv2\n","import PIL\n","from PIL import Image\n","import pathlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvx5yfnBa48O"},"outputs":[],"source":["#Set constants for image size and processing\n","img_height = 32\n","img_width = 32\n","num_classes = 43"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5kHVRKCx9Ho"},"outputs":[],"source":["#Set directory for dataset\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","#unzip the folder to a directory\n","!unzip \"/content/gdrive/MyDrive/Colab Notebooks/archive.zip\" -d path_original"]},{"cell_type":"code","source":["#set data paths\n","data_dir = 'path_original'\n","train_path = 'path_original/Train'\n","test_path = 'path_original/'"],"metadata":{"id":"f5-n05fIcRcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#read in the training data\n","image_data = []\n","image_labels = []\n","\n","for i in range(num_classes):\n","    path = data_dir + '/Train/' + str(i)\n","    images = os.listdir(path)\n","\n","    for img in images:\n","        try:\n","            image = cv2.imread(path + '/' + img)\n","            image_fromarray = Image.fromarray(image, 'RGB')\n","            resize_image = image_fromarray.resize((img_height, img_width))\n","            image_data.append(np.array(resize_image))\n","            image_labels.append(i)\n","        except:\n","            print(\"Error in \" + img)\n","\n","# convert lists to numpy arrays\n","image_data = np.array(image_data)\n","image_labels = np.array(image_labels)"],"metadata":{"id":"FZuS9yGQcSk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#shuffling the training data\n","idx = np.arange(image_data.shape[0])\n","np.random.shuffle(idx)\n","image_data = image_data[idx]\n","image_labels = image_labels[idx]\n","\n","#Creating training and validation sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, train_size=0.8, random_state=101, shuffle=True)\n","\n","#normalize the images\n","#As the pixel values range from 0 to 256, apart from 0 the range is 255. So dividing all the values by 255 will convert it to range from 0 to 1.\n","X_train = X_train/255 \n","X_val = X_val/255\n","\n","#One-hot encoding labels\n","y_train = keras.utils.to_categorical(y_train, 43)\n","y_val = keras.utils.to_categorical(y_val, 43)"],"metadata":{"id":"UCU94c8dcaSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#read in the test data\n","test = pd.read_csv(data_dir + '/Test.csv')\n","\n","labels = test[\"ClassId\"].values\n","imgs = test[\"Path\"].values\n","\n","data =[]\n","\n","for img in imgs:\n","    try:\n","        image = cv2.imread(data_dir + '/' +img)\n","        image_fromarray = Image.fromarray(image, 'RGB')\n","        resize_image = image_fromarray.resize((img_height, img_width))\n","        data.append(np.array(resize_image))\n","    except:\n","        print(\"Error in \" + img)\n","X_test = np.array(data)\n","y_test = labels\n","\n","#normalize by 255\n","X_test = X_test/255\n","y_test = keras.utils.to_categorical(y_test, 43)"],"metadata":{"id":"7wWOEf0xclcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Data augmentation for alternative models\n","data_augment = Sequential([RandomTranslation(height_factor=0.1,width_factor=0.1),\n","                           RandomRotation(0.1),\n","                           RandomZoom(0.1),RandomContrast(0.1)])"],"metadata":{"id":"9k5JPmAOOFgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Specifying and training ResNet\n","i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n","x = tf.cast(i, tf.float32)\n","x = data_augment(i)\n","x = tf.keras.applications.resnet_v2.preprocess_input(x)\n","core = ResNet50V2(include_top=False,weights=None,pooling='avg',input_shape=(64,64,3))\n","x = core(x)\n","base_model = tf.keras.Model(inputs=[i], outputs=[x])\n","resnet = Sequential()\n","resnet.add(base_model)\n","resnet.add(Dropout(0.2))\n","resnet.add(Dense(43, activation='softmax'))\n","resnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","resnet.fit(x=X_train,y = y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))"],"metadata":{"id":"M1GyBd7fN1fe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Specifying and training DenseNet\n","i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n","x = tf.cast(i, tf.float32)\n","x = data_augment(i)\n","x = tf.keras.applications.densenet.preprocess_input(x)\n","core = DenseNet121(include_top=False,weights=None,pooling='avg',input_shape=(64,64,3))\n","x = core(x)\n","base_model = tf.keras.Model(inputs=[i], outputs=[x])\n","densenet = Sequential()\n","densenet.add(base_model)\n","densenet.add(Dropout(0.2))\n","densenet.add(Dense(43, activation='softmax'))\n","densenet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","densenet.fit(x=X_train,y = y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))"],"metadata":{"id":"Bgte5B5rN2am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Specifying and training EfficientNet\n","i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n","x = tf.cast(i, tf.float32)\n","x = data_augment(i)\n","x = tf.keras.applications.efficientnet.preprocess_input(x)\n","core = EfficientNetB0(include_top=False,weights=None,pooling='avg',input_shape=(64,64,3))\n","x = core(x)\n","base_model = tf.keras.Model(inputs=[i], outputs=[x])\n","efficientnet = Sequential()\n","efficientnet.add(base_model)\n","efficientnet.add(Dropout(0.2))\n","efficientnet.add(Dense(43, activation='softmax'))\n","efficientnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","efficientnet.fit(x=X_train,y = y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))"],"metadata":{"id":"QIOj3JlpN25C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Specifying and training Xception\n","i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n","x = tf.cast(i, tf.float32)\n","x = data_augment(i)\n","x = tf.keras.applications.xception.preprocess_input(x)\n","core = Xception(include_top=False,weights=None,pooling='avg',input_shape=(71,71,3))\n","x = core(x)\n","base_model = tf.keras.Model(inputs=[i], outputs=[x])\n","xception = Sequential()\n","xception.add(base_model)\n","xception.add(Dropout(0.2))\n","xception.add(Dense(43, activation='softmax'))\n","xception.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","xception.fit(x=X_train,y = y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))"],"metadata":{"id":"LEuqjKFxN3bF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZKo2n-3rdLK"},"outputs":[],"source":["#Set up our custom model architecture\n","#Trying simple expanded LeNet architecture with C-C-P-C-C-P layering\n","#Using batchnormalization after each convolutional layer\n","\n","model = Sequential()\n","\n","#CNN layer 1\n","model.add(Conv2D(filters=25, kernel_size=(5,5), input_shape=(img_height,img_width,3)))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(Conv2D(filters=25, kernel_size=(5,5)))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(BatchNormalization(axis=-1))\n","\n","#CNN layer 2\n","model.add(Conv2D(filters=50, kernel_size=(3,3)))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(Conv2D(filters=50, kernel_size=(3,3)))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(BatchNormalization(axis=-1))\n","model.add(Dropout(rate=0.3))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(LeakyReLU(alpha=0.01))\n","keras.layers.BatchNormalization()\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(43, activation='softmax'))\n"]},{"cell_type":"code","source":["#Load saved model\n","model = tf.keras.models.load_model('/content/gdrive/MyDrive/Colab Notebooks/cnn6')"],"metadata":{"id":"30l-Zmx9uLWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZZl5CJ6UTcT"},"outputs":[],"source":["#Get summary table of model\n","model.build(input_shape=(None, 32, 32, 3))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C47-VNHIELyz"},"outputs":[],"source":["#Compile model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sopRxbHQETCf"},"outputs":[],"source":["#Create data augmentation\n","augment = ImageDataGenerator(\n","    rotation_range=10,\n","    zoom_range=0.15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    fill_mode=\"nearest\")\n","\n","#Fit model\n","history = model.fit(x=X_train,y = y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))\n","#model.fit(augment.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_val, y_val))"]},{"cell_type":"code","source":["#Plot training and validation acc through epochs\n","plt.plot(history.history['accuracy'],label=\"Training Accuracy\")\n","plt.plot(history.history['val_accuracy'],label=\"Validation Accuracy\")\n","plt.title(\"Learning Curve of Our Model Through 30 Epochs\")\n","plt.legend()\n","plt.savefig(\"learning_curve.png\")"],"metadata":{"id":"xA0tQWnAP7S0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uozUzc-T7QJW"},"outputs":[],"source":["#Save and download model\n","model.save('cnn6')\n","!zip -r /content/cnn6.zip /content/cnn6\n","from google.colab import files\n","files.download(\"/content/cnn6.zip\")"]},{"cell_type":"code","source":["#Evaluate model to get test accuracy\n","model.evaluate(x=X_test,y=y_test)"],"metadata":{"id":"USUoonaEjpQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CPlqKTW9aTs"},"outputs":[],"source":["#Get predictions from model\n","preds = np.argmax(model.predict(x=X_test),axis=1)"]},{"cell_type":"code","source":["#Get classification report on test predictions\n","\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","\n","print(classification_report(test['ClassId'], preds))"],"metadata":{"id":"nB8hwyJsa0a4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting model complexity plots\n","\n","import pandas as pd\n","from io import StringIO\n","times = StringIO(\"\"\"    train    classif    trainable\n","Custom-Simple    15    0.41    630539\n","ResNet50V2    67    0.69    23607467\n","DenseNet121    77    1.34    6997931\n","EfficientNetB0    64    0.75    4062631\n","Xception    99    0.81    20895059\n","\"\"\")\n","times_df = pd.read_csv(times, index_col=0, delimiter=' ', skipinitialspace=True)\n","\n","#Set figure and axes\n","fig = plt.figure() \n","ax = fig.add_subplot(111)\n","ax2 = ax.twinx()\n","\n","#Plot both times on different axes\n","width = 0.3\n","times_df.train.plot(kind='bar', color='teal', ax=ax, width=width, position=1)\n","times_df.classif.plot(kind='bar', color='orange', ax=ax2, width=width, position=0)\n","\n","ax.set_ylabel('Training Time (sec/epoch)')\n","ax2.set_ylabel('Classification Time (ms/image)')\n","plt.title(\"Training and Classification Times for Different CNN Architectures\")\n","\n","plt.savefig('CNN_runtimes.png', bbox_inches=\"tight\")\n","plt.show()\n","\n","#Plot trainable parameters barplot\n","times_df.trainable.plot(kind='bar', color='orange', width=width)\n","plt.title(\"Number of Trainable Parameters for CNN Architectures\", fontsize=10.5)\n","plt.ylabel(\"Trainable Paramters (in 10 millions)\")\n","plt.savefig('CNN_params.png', bbox_inches=\"tight\")"],"metadata":{"id":"DcrP_jWYmitO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting F1 scores vs training data\n","\n","f1_scores = f1_score(test['ClassId'], preds, average=None)\n","\n","train_counts = np.unique(traindf['ClassId'],return_counts=True)[1]\n","\n","plt.scatter(train_counts, f1_scores, color=\"teal\")\n","plt.xlabel(\"Number of Training Images\")\n","plt.ylabel(\"F1-Score\")\n","plt.title(\"F1-Score compared with Amount of Data in Class\")\n","plt.savefig('f1_scores.png', bbox_inches=\"tight\")"],"metadata":{"id":"tBS-veZwXwra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Getting class 27 images\n","class_27 = np.where(np.argmax(y_test,axis=1) == 27)[0]\n","class_27_wrong = np.zeros(0,dtype=int)\n","for i in range(len(class_27)):\n","  if preds[class_27[i]] != 27:\n","    class_27_wrong = np.append(class_27_wrong,class_27[i])"],"metadata":{"id":"GVJ3S18NXoVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(test['ClassId'],preds)[27,11]\n","confusion_matrix(test['ClassId'],preds)[27,21]"],"metadata":{"id":"H1NB2oqurkl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (25, 5))\n","\n","#Print out some wrong predictions for class 27 which had worst performance\n","start_index = 0\n","for i in range(5):\n","    plt.subplot(1, 5, i + 1)\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    prediction = preds[class_27_wrong[i]]\n","    truth = labels[class_27_wrong[i]]\n","    col = 'g'\n","    if prediction != truth:\n","        col = 'r'\n","    plt.xlabel('Actual={} | Pred={}'.format(truth, prediction), color = col, fontsize=20)\n","    plt.imshow(X_test[class_27_wrong[i]])\n","plt.savefig(\"class27_preds.png\")\n","plt.show()\n","\n"],"metadata":{"id":"a6oqVsw1XFaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print out some images from class 21 and 11 to see what could be cause\n","class_11 = np.where(np.argmax(y_test,axis=1)==11)[0]\n","class_21 = np.where(np.argmax(y_test,axis=1)==21)[0]\n","\n","fig = plt.figure(figsize=(25,5))\n","ax1 = fig.add_subplot(1,5,1)\n","ax1.imshow(X_test[class_11[0]])\n","ax1.set_xlabel(\"Class 11\", fontsize=20)\n","ax1.set_xticks([])\n","ax1.set_yticks([])\n","ax2 = fig.add_subplot(1,5,2)\n","ax2.imshow(X_test[class_11[1]])\n","ax2.set_xlabel(\"Class 11\", fontsize=20)\n","ax2.set_xticks([])\n","ax2.set_yticks([])\n","ax3 = fig.add_subplot(1, 5, 3)\n","ax3.imshow(X_test[class_21[0]])\n","ax3.set_xlabel(\"Class 21\", fontsize=20)\n","ax3.set_xticks([])\n","ax3.set_yticks([])\n","ax4 = fig.add_subplot(1, 5, 4)\n","ax4.set_xlabel(\"Class 21\", fontsize=20)\n","ax4.set_xticks([])\n","ax4.set_yticks([])\n","ax4.imshow(X_test[class_21[1]])\n","\n","fig.savefig(\"class11_21.png\")"],"metadata":{"id":"RMF2xpJTerGZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"STA208_Project.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}